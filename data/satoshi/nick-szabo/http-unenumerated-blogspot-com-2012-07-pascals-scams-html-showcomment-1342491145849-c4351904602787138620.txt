Brian H, you'll often save many people from needless nightmaring or
daydreaming if you are able to give good reasons about why it's BS.  
  
In response to the two Anonymi, I wasn't going to name names, but the rapture
or doom of "the Singularity", "SkyNet", "the Matrix", and similar robot
apocalypse scenarios, does seem to fit the bill, especially regarding the
inability of their proponents to design experiments that would give us
information about these ideas that would greatly reduce uncertainties about
them. Instead, they go straight to supposed solutions (per above, as likely to
lead closer to dystopia as to closer to utopia, since the uncertainties about
the underlying causes are so high, falsely precise rhetoric notwithstanding).  
  
I describe the economic and computational efficiency reasons why the odds of
either very useful or very dangerous "general AI" are very long here, see both
the original post and some of my comments below it.

