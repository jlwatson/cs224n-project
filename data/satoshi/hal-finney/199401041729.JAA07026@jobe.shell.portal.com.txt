I use Stacker for disk compression on my PC, and this problem of
un-erased data is potentially worse with that software.  Probably
Microsoft's DoubleSpace suffers from the same problem.

If you erase a file on a compressed partition using some of these
suggestions, such as writing a pattern followed by its complement, you
won't erase the whole file.  That is because a repeated pattern is far
more compressible than the original file contents, in most cases.  A
4K byte text file may compress down to 2K on the disk, but 4K worth of
repetitions of 0xff will compress down to just a few bytes!  The majority
of your file will not be touched at all.

Norton has a "wipefile" program which overwrites files according to a
government standard, but I believe it just writes constant values repeatedly.
This will overwrite only the start of the file, many times.

Bruce Schneier recommends including one or more passes of writing
pseudorandom data to the file.  Since this data is not compressible it
should overwrite the whole file.  The data doesn't have to be cryptographically
random, just something that won't be compressed by straightforward
algorithms.