

Despite everything else said, the current next step is:  

In particular, I suspect that more read caching might help a lot.  
  
Then something more specific was wrong. That's not due to normal initial
download time. Without more details, it can't be diagnosed. If it was due to
slow download, did it speed up after 10-20 minutes when the next block
broadcast should have made it switch to a faster source? debug.log might have
clues. How fast is their Internet connection? Was it steadily slow, or just
slow down at one point?  
  
The 74000 checkpoint is not enough to protect you, and does nothing if the
download is already past 74000. -checkblocks does more, but is still easily
defeated. You still must trust the supplier of the zipfile.  
  
If there was a "verify it" step, that would take as long as the current normal
initial download, in which it is the indexing, not the data download, that is
the bottleneck.  
  
80 bytes per header and no indexing work. Might take 1 minute.  
  
The data is mostly hashes and keys and signatures that are uncompressible.  
  
The speed of initial download is not a reflection of the bulk data transfer
rate of the protocol. The gating factor is the indexing while it downloads.  
  

