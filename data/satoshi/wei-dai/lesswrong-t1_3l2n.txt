I think this paragraph reflects a very serious confusion that is seen on LW regularly: 
&gt; How strongly should I believe P? How should I adjust my probability for P in the face of new evidence X? There is a single, exactly correct answer to each such question, and it is provided by Bayesâ€™ Theorem. We may never know the correct answer, but we can plug estimated numbers into the equation and update our beliefs accordingly. 

Most of your beliefs are not produced by some process that you can break into its component parts and analyze mathematically so as to assign a numerical probability. Rather, they are produced by opaque black-box circuits in your brain, about whose internal functioning you know little or nothing. Often these circuits function very well and let you form very reliable judgments, but without the ability to reverse-engineer and analyze them in detail, which you presently don't have, you cannot know what would be the correct probability (by any definition) assigned to their outputs, except for the vague feeling of certainty that they typically produce along with their results. 

If instead of relying on your brain's internal specialized black-box circuits you use some formal calculation procedure to produce probability estimates, then yes, these numbers can make sense. However, the important points are that: (1) the numbers produced this way do not pertain to the outputs of your brain's opaque circuits, but only to the output of the formal procedure itself, and (2) these opaque circuits, as little as we know about how they actually work, very often produce much more reliable judgments than any formal models we have. Assigning probability numbers produced by explicit formal procedures to beliefs produced by opaque procedures in one's head is a total fallacy, and discarding the latter in favor of the former makes it impossible to grapple with the real world at all. 