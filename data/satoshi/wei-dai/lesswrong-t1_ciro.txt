Can you expand on the Point #7, if that's possible? There are some people, who honestly think Friendliness-researchers in MIRI and other places actually discourage AI research. Which sounds to me ridiculous, I've never seen such attitude from Friendliness-researchers, nor can even imagine that. But this was the primary reason for [Mark Friedenbach's leaving LW](http://lesswrong.com/r/discussion/lw/m81/leaving_lesswrong_for_a_more_rational_life/): he said that there's a massive tendency against solving world problems on LW, specifically because actual AI research is supposedly dangerous. He considered LW a memetic hazard that he doesn't want to participate in. Although I completely disagree on his evaluation of current memes of LW and MIRI, he claimed he received [2 separate death threats](http://lesswrong.com/r/discussion/lw/m81/leaving_lesswrong_for_a_more_rational_life/ceb3) on #lesswrong IRC channel, when mentioned that he wants to do actual AI research.

So if there's somebody who is actually against ongoing AI research, I want to know that. And if that's not an isolated event, but a tendency, even small, MIRI or somebody should make a statement. I mean, people are getting ridiculous distorted ideas of MIRI and LW, and little effort is done to correct them.