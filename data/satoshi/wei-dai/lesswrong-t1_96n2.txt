I'm not truly impressed with GiveWell's general optimization since they never made a good case that malaria was connected to astronomical benefits or, indeed, seem to have realized that such a case is necessary for effective altruism.  But for near-term certain benefits they still think in utilons and do cross-cause comparison of things that will produce those utilons; which puts them far, *far* ahead of a Gates Foundation which AFAICT picks a measurable cause at emotional whim and then optimizes within that cause.  Especially since most of the variance in returns is between causes.  GF's only possible claim to superior impact per dollar for some dollars would have to come from longer-term funding of science and technology, taking on risk and time horizon which Givewell refuses.  But a great deal of GF's funding also goes to near-term utilons obtained by known mechanisms, so they are clearly competing on ground to which Givewell has staked a plausible claim of optimization, and apparently doing so at whim and not by optimization.

I expect of course that no good justification shall be forthcoming of why GF didn't fund the Against Malaria Foundation with a casual wave of their hands, but perhaps you shall call this small Bayesian evidence because of a worry that if this justification existed, GF would be unlikely to publish it.  Givewell is usually pretty open about that sort of thing.  But perhaps GF is more constrained, and does not for PR reasons publish the negative judgments of their secret council of epistemic rationalists.  But then why haven't we seen the positive judgments?  Who would put in Holden's level of cognitive work and then say nothing of that work, and why?  Why keep the reasoning of your effective altruism a secret?

More generally, what would make you update towards "People are crazy, the world is mad"?  When in many cases such as this I see no evidence that the world is sane, I update towards madness.