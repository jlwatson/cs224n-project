In the discussion about AI-based vs. upload-based singularities, and the expected utility of pushing for WBE (whole-brain emulation) first, has it been taken into account that an unfriendly AI is unlikely to do something *worse* than wiping out humanity, while the same isn't necessarily true in an upload-based singularity? I haven't been able to find discussion of this point, yet (unless you think that Robin's [Hardscrapple Frontier](http://hanson.gmu.edu/hardscra.pdf) scenario would be *significantly worse than nonexistence*, which it doesn't feel like, to me).

\[**ETA**: To be clear, I'm not trying to argue anything at this point, I'm honestly asking for more info to help me figure out how to think about this.\]