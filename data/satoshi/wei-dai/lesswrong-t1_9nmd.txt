1. No, but it's only because I think figuring out what my goals are requires solving normative ethics which seems too hard a problem to tackle directly.
2. So my interim long-term goal is to eventually figure out what my actual goals are and achieve them (if it's not a null set) and since that seems most likely to happen if we get a positive Singularity, my medium-term goal is to push the future in that direction.
3. My current big problem is that among people who share my medium-term goal of pushing for a positive Singularity, many don't seem to share my ideas of how best to do it. (Eliezer wants to work on FAI, Holden and Christiano want to generally increase prosperity and empower people, and both of these things seem counterproductive to me.) My current way of trying to solve this problem is to write LW posts to explain my arguments in the hope of resolving the disagreements.
4. Lack of feedback is a big problem for me and I worry a lot about whether I'm being productive or counterproductive towards my goals. Unfortunately I can't think of any systems that I could create to help with this. (ETA: I did write [this post](http://lesswrong.com/lw/6pg/experiment_psychoanalyze_me/) in the hope that LWers can help spot when I'm going off track and help correct my course, but so far nobody has taken up the offer.)