We're taking apart your "mathematical intuition" into something that invents a causal graph (this part is still magic) and a part that updates a causal graph "given that your output is Y" (Pearl says how to do this).

If you literally have the ability to run all of reality excluding yourself as a computer program, I suppose the causal graph part might be moot, since you could just simulate elementary particles directly, instead of approximating them with a high-level causal model.  But then it's not clear how to literally simulate out the whole universe in perfect detail when the inside of your computer is casting gravitational influences outward based on transistors whose exact value you haven't yet computed (since you can't compute all of yourself in advance of computing yourself!).

With different physics and a perfect Cartesian embedding (a la AIXI) you could do this, perhaps.  With a perfect Cartesian embedding and knowledge of the rest of the universe outside yourself, there would be no need for causal graphs of any sort within the theory, I think.  But you would still have to factor out your logical uncertainty in a way which prevented you from concluding "if I choose A6, it must have had higher utility than A7" when considering A6 as an option (as Drescher observes).  After all, if you suffered a brief bout of amnesia afterward, and I told you with trustworthy authority that you *really had* chosen A6, you would conclude that you really must have calculated higher expected utility for it relative to your probability distribution and utility function.

If I believably tell you that Lee Harvey Oswald really didn't shoot JFK, you conclude that someone else did.  But in the counterfactual on our standard causal model, if LHO hadn't shot JFK, no one else would have.  So when postulating that your output is A6 inside the decision function, you've got to avoid certain conclusions that you would in fact come to, if you observed in reality that your output really was A6, like A6 having higher expected utility than A7.  This sort of thing is the domain of causal graphs, which is why I'm assuming that the base model is a causal graph with some logical uncertainty in it.  Perhaps you could come up with a similar but non-causal formalism for pure logical uncertainty, and then this would be very interesting.