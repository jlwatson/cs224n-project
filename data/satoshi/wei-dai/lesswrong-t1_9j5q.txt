I'm a reactionary, not an innovator, dammit!  Reacting against this newfangled antiheroic 'reference class' claim that says we ought to let the world burn because we don't have enough of a hero license!

Ahem.

I'm also really unconvinced by the claim that this work could reasonably have expected net negative consequences.  I'm worried about the dynamics and evidence of GiveDirectly.  But I don't think GD has negative consequences, that would be a huge stretch.  It's *possible maybe* but it's certainly not the arithmetic *expectation* and with that said, I worry that this 'maybe negative' stuff is impeding EA motivation generally, there is much that is ineffectual to be wary of, and missed opportunity costs, but trying to warn people against reverse or negative effects seems pretty perverse for anything that has made it onto Givewell's Top 3, or CFAR, or FHI, or MIRI.  Info that shortens AI timelines should mostly just not be released publicly and I don't see any particularly plausible way for a planet to survive without having some equivalent of MIRI doing MIRI's job, and the math thereof should be started as early as feasible.