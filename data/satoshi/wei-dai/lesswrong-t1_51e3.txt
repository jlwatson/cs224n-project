If I understand this idea correctly, I think the same result can be achieved by manipulating the AI's prior, instead of utility function. Define filter G as:

    G(P)(W0)=P(W0) * P(S0 âˆª S1) / P(S0)
    G(P)(W1)=0

In other words, we can make the AI act as if it's certain that the measurement will come out to be 0 (so it will ignore the possibility of an explosion), by setting the prior probability of the worlds in S1 (where the measurement comes out 1) to be 0, and re-normalizing the probabilities of the worlds in S0 so that everything still adds up to 1.

Am I right that this does essentially the same thing as the proposed F?