&gt;One way of phrasing a moral non-cognitivist position is to say that moral statements are properly thought of as expressions of an individual's utility function rather than sentences describing the world.
&gt;
&gt;Note that 'expressions of an individual's utility function' is not the same as 'sentences describing an individual's utility function'. The latter is something like 'I prefer chocolate to vanilla' the former is something like 'Mmmm chocolate!'. It's how the utility function feels from the inside. And the way a utility function feels from the inside appears to be, or at least involve, emotion.

This seems very plausible, *except* for the fact that we are able to reflect on our emotions and intuitive moral judgements, and to some extent the results of our conscious moral deliberations can override our emotions/intuitions, or even change how our emotions/intuitions work. This simply can't happen if our emotions *are* direct expressions of our utility functions, or what they feel like from the inside.

An analogy with Yvain's [blue-minimizing robot](http://lesswrong.com/lw/6ha/the_blueminimizing_robot/) might help here. Emotions perhaps express the utility function of the "main part" of a human brain, but there's this "side module" that works by its own rules, and can occasionally override/modify the "main part". How to formulate a meta-ethics that applies to the human as a whole still seems puzzling to me.