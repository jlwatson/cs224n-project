&gt; Your first suggestion isn't an additional alternative, it's just a subdivision within 4 or 5.

Perhaps, but it seems like there's a substantive difference between those who believe there are no facts about what all intelligent beings should value and between those who believe that in addition to that, there are also no facts about what humans should value.

&gt; Although I repeatedly use "preferences" and "values" in this post, that was just for convenience rather than trying to imply that morality must have something to do with values.

Could you give an example of one of these positions put in terms that would be inclusive of both consequentialist and non-consequentialist ethical theories?