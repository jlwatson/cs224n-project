&gt; An ontology consisting of Gods, Self, Other People, and Dumb Matter just isn't very different from one consisting of Self, Other People, and Dumb Matter

Benja just [posted a neat proof](http://lesswrong.com/r/discussion/lw/fq0/math_appendix_for_why_you_must_maximize_expected/) of why, if your preferences don't satisfy the axiom of continuity in von Neumann-Morgenstern utility theory, your rational behavior would be almost everywhere identical to the behavior of someone whose continuity-satisfying-preferences simply ignore the "lower priority" aspects of yours.  E.g. if you prefer "X torture plus N dust specks" over "Y torture plus M dust specks" for any X &lt; Y but also for any X==Y, N &lt; M, then you might as well ignore the existence of dust specks because in practical questions there's always going to be some epsilon of probability between X and Y.

But now what if instead of "torture" and "dust specks" we have a lexical preference ordering on "displeasure of God(s)" and "everything else bad", and then we remove the former from the picture?  Suddenly the parts of probability space that you were previously ignoring (except indirectly insofar as you tried to reflect the preferences of God(s) regarding everything else) are now the *only* thing you should care about!

From other frameworks the problem looks even worse: If your previous answer to the is-ought problem was to derive every ethical proposition from the single "ought" axiom "We ought to do what God wants regarding X", and now you're down to zero "ought" axioms, that makes a *huge* difference, no?