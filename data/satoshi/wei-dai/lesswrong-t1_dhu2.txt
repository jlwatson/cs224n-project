I endorse this concern. I do think it is possible to create social value in this way though, especially for relatively simple activities with good alignment between apparent and real benefits, e.g. transferring money / fungible resources to an agent that is trying to do good, or supplying additional tax revenue. So I think there are at least some equilibria where the benefits significantly overwhelm the negative effects, and indeed are a significant fraction of the total loss to the signaler.

I think that reaching a good equilibrium is especially plausible amongst the rationalists/EAs.