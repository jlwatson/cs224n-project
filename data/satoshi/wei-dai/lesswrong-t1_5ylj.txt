I guess it seems bizarre because you're changing your behavior in response to a piece of information that tells you nothing about moral philosophy and nothing about the consequences of the behavior. Or is the idea that there are good consequences from timeless cooperation between conflicting selves, or something? But I'm not seeing any gains from trade here, and cooperation isn't Bostrom and Ord's original justification, as far as I know. The original scenario is about an agent whole-heartedly committed to doing the right thing as defined by some procedure he doesn't know the outcome of. And what if you found out the earlier donation had been a pure behavioral tic of a sort that doesn't respond to cooperation? Would you still treat it as though it had been made by you, or would you treat it as though it had been made by something else? If the Parliamentary Model tells you to put 30% of your effort into saving puppies, is it good enough if 30% of your Everett copies put all their effort into it and 70% put none of their effort into it? If so, how much effort should you expend on research into what your parallel selves are currently up to? I'm very confused here, and I'm sure it's partly because I don't understand the parliamentary model, but I'm not convinced it's wholly because of that.