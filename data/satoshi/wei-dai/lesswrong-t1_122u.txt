Wei, if you want to calculate the *consequence* of an action, you need to know that this computation outputting A1 has something do with box B containing a million dollars (and being obtained by you, for that matter) or that A2 has something to do with the driver in Parfit's Hitchhiker deciding to pick you up and take you to the city.  (And yet hypothetically choosing A6 is *not* used to infer, inside the counterfactual, that A6 actually was better than A7.)

This is what I am saying would get computed via the causal graphs, and which may require actual counterfactual surgery a la Pearl - at least the part where you don't believe that A6 actually was better than A7 or that (hypothetically) deciding to cross the road makes it safe - though you may not need to *re*compute Parfit's Hitchhiker, since this is an updateless decision theory to begin with.