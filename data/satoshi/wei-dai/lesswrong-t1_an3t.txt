&gt;There is a much more principled possibility, which I'll call pseudo-Bayesian decision theory, or PBDT. PBDT can be seen as re-interpreting updating as saying that you're indifferent about what happens in possible worlds in which you don't exist as a conscious observer, rather than ruling out those worlds as impossible given your evidence. 

I can see why you'd rule out being completely indifferent about what happens in possible worlds in which you don't exist, but what about something in between being fully updateless and fully updateful? What if you cared less (but isn't completely indifferent) about worlds in which you don't exist as a conscious observer, or perhaps there are two parts to your utility function, an other-regarding part which is updateless and a self-regarding part which changes as you make observations?

Suppose you face a counterfactual mugging where the dollar amounts are $101 and $100 instead of the standard $10000 and $100. If you're fully updateless then you'd still pay up, but if you cared less about the other world (or just the version of yourself in the other world) then you wouldn't pay. Being fully updateless seems problematic for reasons I explained in [Where do selfish values come from?](http://lesswrong.com/lw/8gk/where_do_selfish_values_come_from/) so I'm forced to consider the latter as a possibility.